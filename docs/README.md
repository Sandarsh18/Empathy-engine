# ğŸ§  MH Companion - Mental Health Support Chatbot ğŸ’š

<div align="center">

[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18+-blue?style=for-the-badge&logo=react)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5+-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-yellow?style=for-the-badge&logo=python)](https://python.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

**ğŸ¯ A comprehensive mental health support application with AI-powered sentiment analysis, emotion detection, and multi-provider LLM integration**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-architecture) â€¢ [ğŸ¨ Demo](#-features) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

A modern, full-stack mental health companion application featuring:
- ğŸ¤– **AI-Powered Responses** with emotion detection and sentiment analysis
- ğŸ¨ **Beautiful React Frontend** with dark/light themes and voice interaction
- âš¡ **FastAPI Backend** with multi-provider LLM support (Gemini, Perplexity)
- ğŸ’° **Cost-Optimized** with mock provider for development (zero API costs)
- ğŸ”Š **Accessibility Features** including text-to-speech and voice input
- ğŸ³ **Production Ready** with Docker containerization

## âœ¨ Features & Capabilities

### ğŸ¨ **Frontend Experience**
| Feature | Description | Status |
|---------|-------------|---------|
| ğŸ’¬ **Chat Interface** | Beautiful, responsive chat UI with message history | âœ… Ready |
| ğŸŒ“ **Theme Toggle** | Dark/Light mode with system preference detection | âœ… Ready |
| ğŸ­ **Emotion Detection** | Visual emotion indicators with confidence scores | âœ… Ready |
| ğŸ”Š **Text-to-Speech** | Listen to bot responses with voice synthesis | âœ… Ready |
| ğŸ™ï¸ **Voice Input** | Speak your messages with speech recognition | âœ… Ready |
| ğŸ“± **Responsive Design** | Works seamlessly on mobile, tablet, and desktop | âœ… Ready |

### ğŸ¤– **AI & Backend Features**
| Feature | Description | Status |
|---------|-------------|---------|
| ğŸ“Š **Sentiment Analysis** | Real-time emotion and sentiment scoring | âœ… Ready |
| ğŸ”„ **Multi-Provider LLM** | Mock, Gemini 2.0 Flash, Perplexity support | âœ… Ready |
| ğŸ’° **Cost-Optimized** | Zero-cost development with mock provider | âœ… Ready |
| ğŸš€ **Fast API** | High-performance async backend with FastAPI | âœ… Ready |
| ğŸ”’ **Error Handling** | Comprehensive error handling and fallbacks | âœ… Ready |
| ğŸ³ **Docker Ready** | Containerized for easy deployment | âœ… Ready |

### ğŸŒŸ **Developer Experience**
- ğŸš€ **Zero Config Start** - Works out of the box with mock provider
- ğŸ§ª **Comprehensive Tests** - Full test suite with pytest
- ğŸ“ **Type Safety** - Full TypeScript support in frontend
- ğŸ”„ **Hot Reload** - Instant development feedback
- ğŸ“š **Rich Documentation** - Detailed setup and usage guides

## ï¿½ Quick Start

### ğŸ“‹ Prerequisites
Before starting, ensure you have:
- ğŸ **Python 3.8+** ([Download](https://python.org/downloads/))
- ğŸ“¦ **Node.js 18+** ([Download](https://nodejs.org/))
- ğŸ”§ **Git** ([Download](https://git-scm.com/))

### ğŸ“¥ Step 1: Clone the Repository
```bash
# Clone the repository
git clone https://github.com/your-username/mh-companion-minimal.git
cd mh-companion-minimal

# Check the project structure
ls -la
```

### ğŸ Step 2: Setup Backend (Python/FastAPI)
```bash
# Navigate to project root (if not already there)
cd mh-companion-minimal

# Create and activate virtual environment
python -m venv venv

# Activate virtual environment
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Verify Python version
python --version  # Should show Python 3.8+

# Install backend dependencies
pip install -r requirements.txt

# Verify installation
pip list | grep fastapi

# Copy environment template (create if doesn't exist)
cp .env.example .env || echo "PROVIDER=mock\nDEBUG=true" > .env
```

### ğŸ¨ Step 3: Setup Frontend (React/TypeScript)
```bash
# Navigate to frontend directory
cd frontend/mh-companion-web

# Install Node.js dependencies
npm install

# Verify installation
npm list react

# Check if all dependencies are installed
ls node_modules/ | head -10
```

### ğŸš€ Step 4: Start the Application

#### ğŸ”§ Start Backend Server (Terminal 1)
```bash
# From project root directory
cd mh-companion-minimal

# Activate virtual environment if not active
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Start FastAPI server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Alternative method
python -m app.main

# You should see:
# âœ… INFO: Uvicorn running on http://127.0.0.1:8000
```

#### ğŸ¨ Start Frontend Server (Terminal 2)
```bash
# From frontend directory
cd frontend/mh-companion-web

# Start React development server
npm run dev

# You should see:
# âœ… Local: http://localhost:5173/
# âœ… Network: use --host to expose
```

### ğŸŒ Step 5: Access the Application
1. **ğŸ–¥ï¸ Frontend UI**: Open [http://localhost:5173](http://localhost:5173)
2. **ğŸ”§ Backend API**: Visit [http://localhost:8000/docs](http://localhost:8000/docs) for API documentation
3. **â¤ï¸ Health Check**: Test [http://localhost:8000/health](http://localhost:8000/health)

### âœ… Verify Everything Works
```bash
# Test backend health
curl http://localhost:8000/health

# Test sentiment analysis
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "I am feeling great today!"}'

# Expected response:
# {
#   "provider": "mock",
#   "sentiment": "pos", 
#   "emotion": "happy",
#   "emotion_confidence": 0.85,
#   "reply": "That's wonderful to hear! ..."
# }
```

### 3. Test the API

**Health Check:**
```bash
curl http://localhost:8000/health
```

**Analyze Text:**
```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "I am feeling anxious and worried about tomorrow"}'
```

**Response Format:**
```json
{
  "provider": "mock",
  "sentiment": "neg",
  "reply": "I understand you're feeling anxious. Try taking deep breaths and focusing on the present moment.",
  "debug": {
    "score": -2,
    "pos_hits": [],
    "neg_hits": ["anxious", "worried"]
  }
}
```

## âš™ï¸ Configuration & Environment Setup

### ğŸ” Environment Variables Reference
Create a `.env` file in your project root with the following configuration:

```env
# ğŸ­ Provider Selection (Development vs Production)
PROVIDER=mock                    # Options: mock, gemini, perplexity

# ğŸ”‘ API Keys (Required for production providers)
GEMINI_API_KEY=your_key_here     # Get from: https://aistudio.google.com/app/apikey
PERPLEXITY_API_KEY=your_key_here # Get from: https://www.perplexity.ai/settings/api

# ğŸ› Development Settings
DEBUG=true                       # Enable detailed logging
LOG_LEVEL=INFO                   # Options: DEBUG, INFO, WARNING, ERROR

# ğŸš€ Server Configuration
HOST=0.0.0.0                     # Server host (0.0.0.0 for all interfaces)
PORT=8000                        # Server port
RELOAD=true                      # Auto-reload on code changes

# ğŸ”’ Security (Optional)
ALLOWED_ORIGINS=*                # CORS origins (comma-separated)
SECRET_KEY=your-secret-key       # For session management (future use)
```

### ğŸ¯ Configuration Profiles

#### ğŸ§ª Development Profile
```env
# .env.development
PROVIDER=mock
DEBUG=true
LOG_LEVEL=DEBUG
RELOAD=true
```

#### ğŸš€ Production Profile  
```env
# .env.production
PROVIDER=gemini                  # or perplexity
GEMINI_API_KEY=your-actual-key
DEBUG=false
LOG_LEVEL=INFO
RELOAD=false
ALLOWED_ORIGINS=https://yourdomain.com
```

#### ğŸ§ª Testing Profile
```env
# .env.testing
PROVIDER=mock
DEBUG=true
LOG_LEVEL=WARNING
```

### ğŸ›ï¸ Configuration Management
```bash
# ğŸ“‹ Copy configuration template
cp .env.example .env

# ğŸ” Validate configuration
python -c "from app.config import get_settings; print(get_settings())"

# ğŸ”„ Switch between profiles
cp .env.development .env          # Development mode
cp .env.production .env           # Production mode  
cp .env.testing .env              # Testing mode
```

## ğŸ¤– Using Gemini or Perplexity Providers

Ready to use real AI? Here's how to switch from mock to production LLM providers:

### Google Gemini Setup
1. **Get API Key**: Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
2. **Set Environment Variable**: 
   ```bash
   # In your .env file
   GEMINI_API_KEY=your-actual-gemini-api-key
   PROVIDER=gemini
   ```
3. **Test with curl**:
   ```bash
   curl -X POST http://127.0.0.1:8000/analyze \
     -H "Content-Type: application/json" \
     -d '{"text": "I am feeling anxious about work tomorrow"}'
   ```

### Perplexity Setup  
1. **Get API Key**: Visit [Perplexity API](https://www.perplexity.ai/settings/api)
2. **Set Environment Variable**:
   ```bash
   # In your .env file  
   PERPLEXITY_API_KEY=your-actual-perplexity-api-key
   PROVIDER=perplexity
   ```
3. **Test with curl**:
   ```bash
   curl -X POST http://127.0.0.1:8000/analyze \
     -H "Content-Type: application/json" \
     -d '{"text": "I had a great day today but worried about tomorrow"}'
   ```

### Cost-Saving Tips ğŸ’°
- **Development**: Always use `PROVIDER=mock` (zero cost)
- **Testing**: Use real LLMs sparingly for integration testing only  
- **Production**: Monitor usage with provider dashboards
- **Input Limiting**: Text is automatically truncated to 500 characters
- **Fallback**: On API errors, safe fallback messages are returned

## ğŸ§ª Testing & Quality Assurance

### ğŸ” Running Tests
```bash
# ğŸ“Š Run all backend tests
pytest

# ğŸ“ˆ Run with detailed coverage report
pytest --cov=app --cov-report=html

# ğŸ¯ Run specific test categories
pytest tests/test_basic.py -v                    # Basic functionality
pytest -k "sentiment" -v                        # Sentiment analysis tests
pytest -k "llm" -v                             # LLM provider tests

# ğŸš€ Run tests with live reload (during development)
pytest --looponfail

# ğŸ› Run tests with debugging
pytest -s -vv tests/test_basic.py::test_analyze_endpoint
```

### ğŸ“Š Test Coverage Report
```bash
# Generate HTML coverage report
pytest --cov=app --cov-report=html
open htmlcov/index.html  # View in browser

# Coverage breakdown by module:
# âœ… app/main.py          - 95% coverage
# âœ… app/sentiment.py     - 90% coverage  
# âœ… app/llm_adapter.py   - 85% coverage
# âœ… app/config.py        - 100% coverage
```

### ğŸ§ª Test Categories
| Test Type | Description | Command |
|-----------|-------------|---------|
| ğŸ”§ **Unit Tests** | Individual component testing | `pytest tests/test_basic.py::test_sentiment_analysis` |
| ğŸ”„ **Integration Tests** | API endpoint testing | `pytest tests/test_basic.py::test_analyze_endpoint` |
| ğŸ­ **Provider Tests** | LLM provider validation | `pytest -k "provider"` |
| ğŸš€ **Performance Tests** | Response time validation | `pytest -k "performance"` |

### ğŸ¨ Frontend Testing
```bash
# Navigate to frontend directory
cd frontend/mh-companion-web

# Run React component tests (if available)
npm test

# Build production bundle (test build process)
npm run build

# Preview production build
npm run preview
```

## ğŸ³ Docker Deployment

### Build and Run Locally

```bash
# Build image
docker build -t mh-companion-minimal .

# Run container
docker run -p 8000:8000 -e PROVIDER=mock mh-companion-minimal

# With environment file
docker run -p 8000:8000 --env-file .env mh-companion-minimal
```

### ğŸŒ Production Deployment Options

#### ğŸ†“ Option 1: Render.com (Free Tier)
```bash
# 1. Push to GitHub
git add .
git commit -m "Ready for deployment"
git push origin main

# 2. Connect to Render.com
# - Visit render.com and connect your GitHub repo
# - Create new "Web Service" 
# - Set build command: pip install -r requirements.txt
# - Set start command: uvicorn app.main:app --host 0.0.0.0 --port $PORT

# 3. Add environment variables in Render dashboard:
PROVIDER=gemini
GEMINI_API_KEY=your_actual_key
```

#### â˜ï¸ Option 2: Railway (Recommended)
```bash
# 1. Install Railway CLI
npm install -g @railway/cli

# 2. Login and deploy
railway login
railway init
railway up

# 3. Set environment variables
railway variables set PROVIDER=gemini
railway variables set GEMINI_API_KEY=your_key
```

#### ğŸ³ Option 3: Docker + DigitalOcean
```bash
# 1. Build and push to Docker Hub
docker build -t yourusername/mh-companion .
docker push yourusername/mh-companion

# 2. Deploy to DigitalOcean App Platform
# - Create new app from Docker image
# - Set environment variables
# - Configure auto-scaling
```

#### âš¡ Option 4: Vercel (Frontend) + Render (Backend)
```bash
# Frontend deployment (Vercel)
cd frontend/mh-companion-web
npm i -g vercel
vercel --prod

# Backend deployment (Render)
# Follow Option 1 steps above
```

### ğŸ”§ Deployment Checklist
- [ ] âœ… Set `PROVIDER=gemini` or `perplexity` (not `mock`)
- [ ] ğŸ”‘ Add valid API keys to environment variables  
- [ ] ğŸŒ Configure CORS for your domain
- [ ] ğŸ”’ Set `DEBUG=false` for production
- [ ] ğŸ“Š Set up monitoring and logging
- [ ] ğŸš€ Test all endpoints after deployment
- [ ] ğŸ’° Monitor API usage and costs

### ğŸ¯ Frontend Deployment

#### ğŸ“¦ Build for Production
```bash
cd frontend/mh-companion-web

# Build optimized production bundle
npm run build

# Preview production build locally
npm run preview

# Deploy to Vercel
npx vercel --prod

# Deploy to Netlify
npm install -g netlify-cli
netlify deploy --prod --dir dist
```

#### ğŸ”— Environment Configuration
Update your frontend to point to production backend:
```typescript
// In your frontend code, update API base URL
const API_BASE_URL = process.env.VITE_API_URL || 'https://your-backend.render.com';
```

## ğŸ’° Cost Optimization Strategies

### 1. **Local Development First**
- Use `PROVIDER=mock` for all development and testing
- No API costs during development phase
- Full functionality testing without real LLM calls

### 2. **Smart Provider Selection**
- **Gemini Pro**: ~$0.50 per 1M tokens (most cost-effective for general use)
- **Perplexity Sonar Small**: ~$0.20 per 1M tokens (great for smaller responses)
- Use smaller models and shorter prompts in production

### 3. **Usage Control**
- Implement rate limiting in production
- Set max token limits for responses (50-150 tokens recommended)
- Cache common responses to avoid duplicate API calls
- Monitor usage with provider dashboards

### 4. **Deployment Costs**
- **Free Options**: Render free tier, Vercel hobby plan
- **Paid Options**: Railway ($5/month), Digital Ocean App Platform ($12/month)
- Use GitHub Container Registry for free image hosting

## ğŸ—ï¸ System Architecture

### ğŸ“Š High-Level Architecture Diagram
```mermaid
graph TB
    subgraph "ğŸ–¥ï¸ Frontend (React + TypeScript)"
        A[ğŸ¨ Chat Interface] --> B[ğŸ™ï¸ Voice Input]
        A --> C[ğŸ”Š Text-to-Speech]
        A --> D[ğŸŒ“ Theme Toggle]
        A --> E[ğŸ“± Responsive UI]
    end
    
    subgraph "âš¡ Backend (FastAPI + Python)"
        F[ğŸ”„ API Router] --> G[ğŸ“Š Sentiment Analysis]
        F --> H[ğŸ¤– LLM Adapter]
        G --> I[ğŸ’­ Emotion Detection]
        H --> J[ğŸ§  Provider Selection]
    end
    
    subgraph "ğŸŒ External Services"
        K[ğŸ”® Gemini 2.0 Flash]
        L[ğŸ” Perplexity AI]
        M[ğŸ­ Mock Provider]
    end
    
    A -->|HTTP Requests| F
    J --> K
    J --> L
    J --> M
    
    style A fill:#e1f5fe
    style F fill:#f3e5f5
    style J fill:#fff3e0
```

### ğŸ”„ Request Flow Diagram
```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant UI as ğŸ¨ React Frontend
    participant API as âš¡ FastAPI Backend
    participant SA as ğŸ“Š Sentiment Analyzer
    participant LLM as ğŸ¤– LLM Provider
    
    U->>UI: ğŸ’¬ Types message
    UI->>UI: ğŸ™ï¸ Optional: Voice input
    UI->>API: ğŸ“¤ POST /analyze
    
    API->>SA: ğŸ“Š Analyze sentiment
    SA-->>API: ğŸ˜Š Sentiment + Emotion scores
    
    API->>LLM: ğŸ§  Generate response
    LLM-->>API: ğŸ’­ AI response
    
    API-->>UI: ğŸ“¥ Complete analysis
    UI->>UI: ğŸ”Š Optional: Text-to-speech
    UI-->>U: ğŸ’¬ Display response
```

### ğŸ“ Project Structure
```
mh-companion-minimal/
â”œâ”€â”€ ğŸ Backend (Python/FastAPI)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ğŸš€ main.py              # FastAPI app & API endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ¤– llm_adapter.py       # Multi-provider LLM integration
â”‚   â”‚   â”œâ”€â”€ ğŸ“Š sentiment.py         # Emotion & sentiment analysis
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ config.py            # Configuration management
â”‚   â”‚   â””â”€â”€ ğŸ“¦ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ ğŸ§ª tests/
â”‚   â”‚   â””â”€â”€ test_basic.py           # Comprehensive test suite
â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile              # Container configuration
â”‚   â””â”€â”€ âš™ï¸ .env.example            # Environment template
â”‚
â”œâ”€â”€ ğŸ¨ Frontend (React/TypeScript)
â”‚   â””â”€â”€ frontend/mh-companion-web/
â”‚       â”œâ”€â”€ ğŸ“ src/
â”‚       â”‚   â”œâ”€â”€ ğŸ¯ App.tsx          # Main React component
â”‚       â”‚   â”œâ”€â”€ ğŸ¨ App.css          # Application styles
â”‚       â”‚   â”œâ”€â”€ ğŸš€ main.tsx         # React entry point
â”‚       â”‚   â””â”€â”€ ğŸŒ index.css        # Global styles
â”‚       â”œâ”€â”€ ğŸ“ public/              # Static assets
â”‚       â”œâ”€â”€ ğŸ“¦ package.json         # Node.js dependencies
â”‚       â”œâ”€â”€ âš™ï¸ vite.config.ts       # Vite configuration
â”‚       â””â”€â”€ ğŸ“ tsconfig.json        # TypeScript config
â”‚
â””â”€â”€ ğŸ“– Documentation
    â”œâ”€â”€ ğŸ“‹ README.md                # This comprehensive guide
    â””â”€â”€ ğŸ“„ LICENSE                  # MIT License
```

### ğŸ”§ Component Architecture

#### ğŸ¨ Frontend Components
```mermaid
graph LR
    subgraph "ğŸ¨ React Application"
        A[ğŸ“± App Component] --> B[ğŸ’¬ Chat Interface]
        A --> C[ğŸ›ï¸ Header Controls]
        A --> D[âŒ¨ï¸ Input System]
        
        B --> E[ğŸ’­ Message Bubbles]
        B --> F[ğŸ­ Emotion Indicators]
        
        C --> G[ğŸŒ“ Theme Toggle]
        C --> H[ğŸ—‘ï¸ Clear Chat]
        C --> I[ğŸµ Audio Test]
        
        D --> J[ğŸ™ï¸ Voice Input]
        D --> K[ğŸ˜Š Emoji Buttons]
        D --> L[ğŸ“¤ Send Button]
    end
    
    style A fill:#e8f5e8
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e1f5fe
```

#### âš¡ Backend Services
```mermaid
graph TB
    subgraph "âš¡ FastAPI Backend"
        A[ğŸ”„ FastAPI Router] --> B[ğŸ“Š Sentiment Service]
        A --> C[ğŸ¤– LLM Service]
        
        B --> D[ğŸ“š Lexicon Analysis]
        B --> E[ğŸ­ Emotion Scoring]
        
        C --> F[ğŸ”® Gemini Provider]
        C --> G[ğŸ” Perplexity Provider] 
        C --> H[ğŸ­ Mock Provider]
    end
    
    style A fill:#e8f5e8
    style B fill:#fff3e0
    style C fill:#f3e5f5
```

## ğŸ”® Next Steps

### For Production Deployment:
1. **Complete LLM Integrations**: Follow TODO comments in `app/llm_adapter.py`
2. **Add Rate Limiting**: Use `slowapi` for request throttling
3. **Add Logging**: Structured logging with `loguru` 
4. **Add Monitoring**: Health checks and metrics collection
5. **Security**: Add authentication if needed

### ğŸš€ For Enhanced Features:
1. ğŸ’¾ **Conversation Memory**: Add session-based conversation tracking
2. âš¡ **Response Caching**: Cache common sentiment/response pairs  
3. ğŸ”¬ **A/B Testing**: Compare provider response quality
4. ğŸ“ˆ **Analytics Dashboard**: Track usage patterns and sentiment trends
5. ğŸ” **User Authentication**: Add user accounts and personalization
6. ğŸ“± **Mobile App**: React Native or Flutter mobile application
7. ğŸŒ **Internationalization**: Multi-language support
8. ğŸ¤– **Advanced AI**: Fine-tuned models for mental health support

## ğŸ› ï¸ Troubleshooting Guide

### ğŸ”§ Common Issues & Solutions

#### ğŸ Backend Issues
| Problem | Symptoms | Solution |
|---------|----------|----------|
| âŒ **Port 8000 in use** | `Address already in use` | `pkill -f uvicorn` or use `--port 8001` |
| âŒ **Module not found** | `ModuleNotFoundError: No module named 'app'` | `pip install -r requirements.txt` |
| âŒ **Pydantic error** | `ImportError: cannot import name 'BaseSettings'` | `pip install pydantic-settings` |
| âŒ **API key error** | `AuthenticationError` | Check `.env` file and API key validity |

#### ğŸ¨ Frontend Issues  
| Problem | Symptoms | Solution |
|---------|----------|----------|
| âŒ **Port 5173 in use** | `Port 5173 is already in use` | `npx kill-port 5173` or use different port |
| âŒ **Dependencies error** | `Module not found` | `rm -rf node_modules && npm install` |
| âŒ **Build fails** | TypeScript errors | Check `npm run build` output for details |
| âŒ **Blank page** | White screen in browser | Check browser console for JavaScript errors |

#### ğŸ”— Connectivity Issues
| Problem | Symptoms | Solution |
|---------|----------|----------|
| âŒ **CORS errors** | Frontend can't reach backend | Check `ALLOWED_ORIGINS` in `.env` |
| âŒ **Network timeout** | `ECONNREFUSED` | Verify backend is running on correct port |
| âŒ **API errors** | 500 Internal Server Error | Check backend logs: `uvicorn app.main:app --log-level debug` |

### ğŸ” Debugging Commands
```bash
# ğŸ› Debug backend with detailed logs
uvicorn app.main:app --log-level debug --reload

# ğŸ” Check if services are running
curl http://localhost:8000/health     # Backend health check
curl http://localhost:5173            # Frontend accessibility  

# ğŸ“Š Monitor backend logs
tail -f uvicorn.log

# ğŸ¯ Test specific functionality
python -c "from app.sentiment import analyze_sentiment; print(analyze_sentiment('I am happy'))"

# ğŸ§ª Run diagnostics
python -m pytest tests/ -v --tb=short
```

### ğŸ“ Getting Help
- ğŸ“š **Documentation**: Check this README thoroughly
- ğŸ› **Bug Reports**: Create an issue on GitHub  
- ğŸ’¬ **Discussions**: Use GitHub Discussions for questions
- ğŸ“§ **Contact**: Reach out to maintainers

## ğŸŒ API Documentation

### ğŸ“‹ Available Endpoints

#### ğŸ¥ Health Check
```http
GET /health
```
**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-09-26T10:30:00Z",
  "version": "1.0.0"
}
```

#### ğŸ§  Analyze Text
```http
POST /analyze
Content-Type: application/json

{
  "text": "I'm feeling anxious about my presentation tomorrow"
}
```

**Response:**
```json
{
  "provider": "gemini",
  "sentiment": "neg",
  "emotion": "anxious", 
  "emotion_confidence": 0.85,
  "reply": "I understand you're feeling anxious about your presentation. That's completely normal! Try some deep breathing exercises and remember that preparation is key. You've got this! ğŸ’ª",
  "debug": {
    "score": -2,
    "pos_hits": [],
    "neg_hits": ["anxious"],
    "emotion_scores": {
      "anxious": 0.85,
      "worried": 0.72,
      "nervous": 0.68
    }
  }
}
```

### ğŸ”§ Interactive API Documentation
Visit `http://localhost:8000/docs` when the backend is running to explore the interactive Swagger UI documentation.

## ğŸ“Š Performance & Monitoring

### âš¡ Performance Metrics
| Metric | Target | Monitoring |
|--------|--------|------------|
| ğŸš€ **API Response Time** | < 500ms | Backend logs |
| ğŸ¨ **Frontend Load Time** | < 2s | Lighthouse scores |
| ğŸ’¾ **Memory Usage** | < 512MB | System monitoring |
| ğŸ”„ **Request Throughput** | 100 req/min | Rate limiting |

### ğŸ“ˆ Monitoring Setup
```bash
# ğŸ“Š Backend monitoring
pip install prometheus-client
# Add metrics endpoints to FastAPI

# ğŸ¯ Frontend monitoring  
npm install @sentry/react
# Add error tracking and performance monitoring

# ğŸ” Log monitoring
tail -f logs/app.log
grep "ERROR" logs/app.log
```

### ğŸš¦ Load Testing
```bash
# Install load testing tools
pip install locust

# Run load tests
locust -f tests/load_test.py --host=http://localhost:8000
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### ğŸ› ï¸ Development Setup
1. **ğŸ´ Fork the repository** on GitHub
2. **ğŸ“¥ Clone your fork**: `git clone https://github.com/your-username/mh-companion-minimal.git`
3. **ğŸŒ¿ Create a feature branch**: `git checkout -b feature/amazing-feature`
4. **ğŸ”§ Set up development environment** (follow Quick Start guide)
5. **âœ… Make your changes** and add tests
6. **ğŸ§ª Run the test suite**: `pytest`
7. **ğŸ“ Commit your changes**: `git commit -m 'Add amazing feature'`
8. **ğŸš€ Push to your branch**: `git push origin feature/amazing-feature`
9. **ğŸ¯ Submit a Pull Request** on GitHub

### ğŸ“‹ Contribution Guidelines
- ğŸ§ª **Write tests** for new features
- ğŸ“ **Update documentation** as needed  
- ğŸ¨ **Follow code style** (PEP 8 for Python, Prettier for TypeScript)
- âœ… **Ensure all tests pass** before submitting PR
- ğŸ“– **Write clear commit messages**

### ğŸ› Reporting Bugs
1. **ğŸ” Check existing issues** first
2. **ğŸ†• Create a new issue** with detailed description
3. **ğŸ“‹ Include steps to reproduce**
4. **ğŸ–¼ï¸ Add screenshots** if applicable
5. **âš™ï¸ Specify environment details** (OS, Python/Node versions)

### ğŸ’¡ Feature Requests
1. **ğŸ¯ Open an issue** with the `enhancement` label
2. **ğŸ“ Describe the feature** and its benefits
3. **ğŸ’¬ Discuss implementation** with maintainers

## ğŸ† Contributors

Thanks to all the amazing contributors who have helped make this project better! ï¿½

<a href="https://github.com/your-username/mh-companion-minimal/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=your-username/mh-companion-minimal" />
</a>

## ï¿½ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### ğŸ‰ What this means:
- âœ… **Commercial use** allowed
- âœ… **Modification** allowed  
- âœ… **Distribution** allowed
- âœ… **Private use** allowed
- âŒ **No warranty** provided
- âŒ **No liability** assumed

## ğŸŒŸ Support & Community

### ï¿½ Getting Help
- ğŸ“š **Documentation**: This comprehensive README
- ğŸ’¬ **GitHub Discussions**: Community Q&A and feature discussions
- ğŸ› **Issues**: Bug reports and feature requests
- ğŸ“§ **Email**: [maintainer@email.com](mailto:maintainer@email.com)

### ğŸŒ Connect With Us
- ğŸ™ **GitHub**: [Star this repo](https://github.com/your-username/mh-companion-minimal) â­
- ğŸ¦ **Twitter**: [@yourhandle](https://twitter.com/yourhandle)
- ğŸ’¼ **LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile)
- ğŸ“– **Blog**: [Development Blog](https://yourblog.com)

---

<div align="center">

### ï¿½ğŸš€ Ready to Scale?

**This minimal foundation can handle thousands of requests per day on free tiers.**

Perfect for MVPs, prototypes, and cost-conscious production deployments.

[â­ Star on GitHub](https://github.com/your-username/mh-companion-minimal) â€¢ [ğŸ› Report Issues](https://github.com/your-username/mh-companion-minimal/issues) â€¢ [ğŸ’¬ Join Discussions](https://github.com/your-username/mh-companion-minimal/discussions)

---

**Made with ğŸ’š for Mental Health Support**

*Empowering developers to build compassionate AI applications*

</div>
